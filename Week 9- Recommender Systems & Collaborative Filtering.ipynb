{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e7a08c63",
   "metadata": {},
   "source": [
    "## Recommender Systems"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8769ab9c",
   "metadata": {},
   "source": [
    "Notation:\n",
    "Eg: Predicting movie ratings\n",
    "- $n_u = \\text{no. of users}$\n",
    "- $n_m = \\text{no. of movies}$\n",
    "- $r_{(i,j)} = \\text{1 if user $j$ has rated movie $i$}$\n",
    "- $y^{(i,j)} = \\text{rating given by user $j$ to movie $i$ defined only if $r(i,j) = 1$}$\n",
    "- $n = \\text{no. of features}$\n",
    "- $w^{(j)}, b^{(j)} = \\text{parameters for user $j$}$\n",
    "- $x^{(i)} = \\text{feature vector for movie $i$}$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92711150",
   "metadata": {},
   "source": [
    "## 1. Collaborative Filtering"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "453ff4b3",
   "metadata": {},
   "source": [
    "- If we have features of the movie:\n",
    "- $n = \\text{no. of features}$\n",
    "\n",
    "<img  src=\"./images/Wk9_1.png\"  style=\" width:70%; padding: 10px 20px ; \">    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "004f0e0c",
   "metadata": {},
   "source": [
    "### 1A. Cost function\n",
    "\n",
    "For user $j$ and movie $i$, predict rating: $w^{(j)} \\centerdot x^{(i)} + b^{(j)}$  \n",
    "$m^{(j)} = \\text{no. of movies rated by user $j$}$  \n",
    "\n",
    "\n",
    "To learn $w^{(j)}, b^{(j)}$\n",
    "\n",
    "<img  src=\"./images/Wk9_2.png\"  style=\" width:70%; padding: 10px 20px ; \">    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b124c5b",
   "metadata": {},
   "source": [
    "### 1B. Collaborative Filtering Algorithm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0754bf6",
   "metadata": {},
   "source": [
    "- What if we didn't have $x_1,x_2$? But have parameters?\n",
    "<img  src=\"./images/Wk9_3.png\"  style=\" width:70%; padding: 10px 20px ; \">    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93af74ba",
   "metadata": {},
   "source": [
    "Thus, we need to learn the feature vector by minimising the cost function as function of $x_i$\n",
    "\n",
    "$$\\text{Given }w^{1},b^{1},w^{2},b^{2},...,w^{n_u},b^{n_u}$$\n",
    "<img  src=\"./images/Wk9_4.png\"  style=\" width:70%; padding: 10px 20px ; \">    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f00d524",
   "metadata": {},
   "source": [
    "Combining both cost functions, we get\n",
    "<img  src=\"./images/Wk9_5.png\"  style=\" width:70%; padding: 10px 20px ; \">    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e071c41b",
   "metadata": {},
   "source": [
    "We then run gradient descent:\n",
    "<img  src=\"./images/Wk9_6.png\"  style=\" width:70%; padding: 10px 20px ; \">    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "251492e5",
   "metadata": {},
   "source": [
    "**Summary**: It is called collaborative filtering, due to the nature of having many users/ collabaration between users to determine its own parameters, and the feature vector $x$ for each movie to determine the nature of the movie based on ratings"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bb9f9b4",
   "metadata": {},
   "source": [
    "### 1C. Collaborative filtering for binary labels: favs/likes/clicks"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c45a108f",
   "metadata": {},
   "source": [
    "Binary labels used (liked/disliked)\n",
    "- 1 - Positive/ Engaged\n",
    "- 0 - Negative/ Did not engage\n",
    "- ? - Not interacted / Not yet shown"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "561a3b19",
   "metadata": {},
   "source": [
    "Predict probability of $y^{(i,j)} = 1$ as $g(w^{(j)} \\centerdot x^{(i)} + b^{(j)})$  \n",
    "where $g(z) = \\frac{1}{1 + e^{-z}}$\n",
    "\n",
    "**Notice Logistic Regression Model!**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e3dd162",
   "metadata": {},
   "source": [
    "#### Cost function for binary application"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75b9c3ff",
   "metadata": {},
   "source": [
    "<img  src=\"./images/Wk9_7.png\"  style=\" width:70%; padding: 10px 20px ; \">    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ad225d5",
   "metadata": {},
   "source": [
    "### 1D: Implementation Tips: Mean Normalisation\n",
    "- Without mean normalisation, users default (without having rated any movie) would be 0, which is not fair"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bf923e1",
   "metadata": {},
   "source": [
    "<img  src=\"./images/Wk9_8.png\"  style=\" width:70%; padding: 10px 20px ; \">    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48130e4b",
   "metadata": {},
   "source": [
    "> **Normalisation sets users default to mean rating of each movie.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30bcb6e0",
   "metadata": {},
   "source": [
    "## 2. TensorFlow Implementation\n",
    "- TensorFlow excels in gradient descent, which is used for optimising our cost function to find best parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "549d8fd7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\scipy\\__init__.py:155: UserWarning: A NumPy version >=1.18.5 and <1.25.0 is required for this version of SciPy (detected version 1.26.2\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\User\\anaconda3\\lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a94852a",
   "metadata": {},
   "source": [
    "### 2A. Custom Training Loop \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "510f68f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<tf.Variable 'Variable:0' shape=() dtype=float32, numpy=1.2652391>\n"
     ]
    }
   ],
   "source": [
    "w = tf.Variable(3.0)\n",
    "x = 1.0\n",
    "y = 1.0\n",
    "alpha = 0.01\n",
    "\n",
    "iterations = 100\n",
    "\n",
    "for iter in range(iterations):\n",
    "    # Use TF's Gradient tape to record the steps\n",
    "    #Used to compute cost J, to enable auto differentiation\n",
    "    \n",
    "    with tf.GradientTape() as tape:\n",
    "        fwb = w*x\n",
    "        costJ = (fwb - y) ** 2\n",
    "        \n",
    "    #Use gradient taope to calculate gradients\n",
    "    #of the cost with respect to parameter w\n",
    "    [dJdw] = tape.gradient(costJ, [w])\n",
    "    \n",
    "    #Run one step of gradient descent by updating w to reduce cost\n",
    "    w.assign_add(-alpha * dJdw)\n",
    "    \n",
    "    \n",
    "print(w)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9f824f4",
   "metadata": {},
   "source": [
    "#### Collaborative Filtering using AutoDiff\n",
    "- Can also use Adam optimisation algorithm instead of Gradient Descent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2f2c08d1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\n# Set Initial Parameters (W, X), use tf.Variable to track these variables\\ntf.random.set_seed(1234) # for consistent results\\nW = tf.Variable(tf.random.normal((num_users,  num_features),dtype=tf.float64),  name='W')\\nX = tf.Variable(tf.random.normal((num_movies, num_features),dtype=tf.float64),  name='X')\\nb = tf.Variable(tf.random.normal((1,          num_users),   dtype=tf.float64),  name='b')\\n\\n# Reload ratings and add new ratings\\nY, R = load_ratings_small()\\n#Concatenate user ratings/R(0,1) COLUMN to the left\\nY    = np.c_[my_ratings, Y]\\nR    = np.c_[(my_ratings != 0).astype(int), R]\\n\\n# Normalize the Dataset (minus mean and stuff)\\nYnorm, Ymean = normalizeRatings(Y, R)\\nmy_ratings = np.zeros(num_movies)   \\n\\n\\n\\n# Instantiate a optimizer\\noptimizer = keras.optimizers.Adam(learning_rate = 1e-1)\\niterations = 200\\nlambda_ = 1\\n\\nfor iter in range(iterations):\\n    #Gradient Tape\\n    with tf.GradientTape() as tape:\\n        \\n        #Compute cost (forward pass included in cost)\\n        cost_value = cofiCostFuncV(X, W, b, Ynorm, R, lambda_)\\n        \\n    grads = tape.gradient(cost_value, [X,W,b])\\n    \\n    optimizer.apply_gradients(zip(grads, [X, W, b]))\\n    \\n\""
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def cofiCostFuncV(X, W, b, Y, R, lambda_):\n",
    "    \"\"\"\n",
    "    Returns the cost for the content-based filtering\n",
    "    Vectorized for speed. Uses tensorflow operations to be compatible with custom training loop.\n",
    "    Args:\n",
    "      X (ndarray (num_movies,num_features)): matrix of item features\n",
    "      W (ndarray (num_users,num_features)) : matrix of user parameters\n",
    "      b (ndarray (1, num_users)            : vector of user parameters\n",
    "      Y (ndarray (num_movies,num_users)    : matrix of user ratings of movies\n",
    "      R (ndarray (num_movies,num_users)    : matrix, where R(i, j) = 1 if the i-th movies was rated by the j-th user\n",
    "      lambda_ (float): regularization parameter\n",
    "    Returns:\n",
    "      J (float) : Cost\n",
    "    \"\"\"\n",
    "    j = (tf.linalg.matmul(X, tf.transpose(W)) + b - Y)*R\n",
    "    #reduce_sum- sums up all the terms in the matrix\n",
    "    J = 0.5 * tf.reduce_sum(j**2) + (lambda_/2) * (tf.reduce_sum(X**2) + tf.reduce_sum(W**2))\n",
    "    return J\n",
    "\n",
    "'''\n",
    "# Set Initial Parameters (W, X), use tf.Variable to track these variables\n",
    "tf.random.set_seed(1234) # for consistent results\n",
    "W = tf.Variable(tf.random.normal((num_users,  num_features),dtype=tf.float64),  name='W')\n",
    "X = tf.Variable(tf.random.normal((num_movies, num_features),dtype=tf.float64),  name='X')\n",
    "b = tf.Variable(tf.random.normal((1,          num_users),   dtype=tf.float64),  name='b')\n",
    "\n",
    "# Reload ratings and add new ratings\n",
    "Y, R = load_ratings_small()\n",
    "#Concatenate user ratings/R(0,1) COLUMN to the left\n",
    "Y    = np.c_[my_ratings, Y]\n",
    "R    = np.c_[(my_ratings != 0).astype(int), R]\n",
    "\n",
    "# Normalize the Dataset (minus mean and stuff)\n",
    "Ynorm, Ymean = normalizeRatings(Y, R)\n",
    "my_ratings = np.zeros(num_movies)   \n",
    "\n",
    "\n",
    "\n",
    "# Instantiate a optimizer\n",
    "optimizer = keras.optimizers.Adam(learning_rate = 1e-1)\n",
    "iterations = 200\n",
    "lambda_ = 1\n",
    "\n",
    "for iter in range(iterations):\n",
    "    #Gradient Tape\n",
    "    with tf.GradientTape() as tape:\n",
    "        \n",
    "        #Compute cost (forward pass included in cost)\n",
    "        cost_value = cofiCostFuncV(X, W, b, Ynorm, R, lambda_)\n",
    "        \n",
    "    grads = tape.gradient(cost_value, [X,W,b])\n",
    "    \n",
    "    optimizer.apply_gradients(zip(grads, [X, W, b]))\n",
    "    \n",
    "'''\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae3b8a1b",
   "metadata": {},
   "source": [
    "#### Why cant we use a regular neural network? (Sequential, Compile, Fit)\n",
    "A: Collaborative filtering algorithm and cost function doesnt fit into standard NN/ Dense format. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89cb183f",
   "metadata": {},
   "source": [
    "### 2B. Finding related items\n",
    "Eg: How to find similar movies using the collaborative filtering?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2211d318",
   "metadata": {},
   "source": [
    "Features $x^{(i)}$ of item $i$ are quite hard to interpret.  \n",
    "To find other items related to it, we need to find item $k$ with $x^{(k)}$ similar to $x{(i)}$ by finding:\n",
    "<img  src=\"./images/Wk9_9.png\"  style=\" width:70%; padding: 10px 20px ; \">    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb5c3a03",
   "metadata": {},
   "source": [
    "### 2C. Limitations of Collaborative Filtering\n",
    "* Cold start problem. How to:\n",
    "    * Rank new items that few users rated?\n",
    "    * Show reasonable items to users who have rated very few items?\n",
    "    \n",
    "* Use side info about items/ users:\n",
    "    * Item: Genre, movie stars, studio\n",
    "    * User: Demographics (age, gender, location), expressed preferences),..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "217c0261",
   "metadata": {},
   "source": [
    "## 3. Content-based Filtering"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec3b8ee3",
   "metadata": {},
   "source": [
    "### 3A. Collaborative filtering vs Content-based filtering\n",
    "\n",
    "* Collbaorative Filtering:\n",
    "    * Recommend items to you based on **rating** of users who gave similar ratings as you\n",
    "\n",
    "* Content-based Filtering\n",
    "    * Recommend items to you based on **features** of users and item to find a good match"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54b9c79b",
   "metadata": {},
   "source": [
    "- User features: $x_u^{j}$ for user $j$\n",
    "    * Age, Gender, Movies Watched, Country, Average rating per genre\n",
    "- Movie features: $x_m^{i}$ for movie $i$\n",
    "    * Year, Genre, Reviews, ...\n",
    "    \n",
    "**Use one-hot encoding for features when necessary**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27b7faef",
   "metadata": {},
   "source": [
    "<img  src=\"./images/Wk9_10.png\"  style=\" width:70%; padding: 10px 20px ; \">    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6bf6022",
   "metadata": {},
   "source": [
    "**Note: $x_u^{j}$ and $x_m^{i}$ might differ in size, but $v_u^{j}$ and $v_m^{i}$ must be of same size for dot product**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db3fb67f",
   "metadata": {},
   "source": [
    "### 3B. Deep-learning for content-based filtering using Neural Network\n",
    "#### Neural Network Architecture\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf8c5bf5",
   "metadata": {},
   "source": [
    "Convert $x_u$ to vector $v_u$ ; $x_m$ to vector $v_m$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d32b894",
   "metadata": {},
   "source": [
    "**User Network** $x_u$ to vector $v_u$\n",
    "- Sequential (Dense NNL(128u) , ..., ) > $v_u$ (32 units)\n",
    "\n",
    "**Movie Network** $x_m$ to vector $v_m$\n",
    "- Sequential (Dense NNL(256u), ..., ) > $v_m$ (32 units **same as above**)\n",
    "\n",
    "**Prediction: $g(v_u \\centerdot v_m)$ to predict that probability $y^{(i,j)}$ is 1**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac921205",
   "metadata": {},
   "source": [
    "<img  src=\"./images/Wk9_11.png\"  style=\" width:70%; padding: 10px 20px ; \"> "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d860de0",
   "metadata": {},
   "source": [
    "With user and item vectors ($v_u^{(j)}, v_m^{(i)}$),\n",
    "\n",
    "- To find movies similar to movie $i$:\n",
    "    * Ensure $(v_m^{(k)} - v_m^{(i)})^2$ is small\n",
    "    * Example of combining/ putting two neural networks to form complex architecture\n",
    "    * **Note: This can be pre-computed ahead of time (while user is inactive)**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40ca9c8a",
   "metadata": {},
   "source": [
    "### 3C. Recommending from a large catalogue"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56f5f638",
   "metadata": {},
   "source": [
    "- Might be computationally expensive/infeasible\n",
    "- Need to be find recommendation efficiently from a large set of items\n",
    "- Involves two main steps: **Retrieval & Ranking**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8d6e45b",
   "metadata": {},
   "source": [
    "1. Retrieval\n",
    "    * Generate large list of plausible item candidates\n",
    "    * Eg: Similar movies watched, top movies for most viewed genre, country's top movies\n",
    "    * Combine items in list and filter duplicates/watched\n",
    "    * Trade-off: More items > **Better performance**, but **Slower Recommendations**\n",
    "    * Optimise trade-off by conducting offline experiments to see if retrieving more items > more relevant recommendations (i.e. $p(y^{(i,j)} = 1)$ is higher)\n",
    "\n",
    "2. Ranking\n",
    "    * Take list retrieved and rank using learned model\n",
    "    * Display ranked items to user (based on predicted user rating)\n",
    "    * $x_m$ can be computed before hand"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a162dc04",
   "metadata": {},
   "source": [
    "### 3D. TensorFlow Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdef596e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import Model\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Input, Dot\n",
    "from tensorflow.keras.losses import MeanSquaredError\n",
    "\n",
    "user_NN = Sequential([\n",
    "    Dense(256, activation = 'relu'),\n",
    "    Dense(128, activation = 'relu'),\n",
    "    Dense(32),\n",
    "])\n",
    "\n",
    "item_NN = Sequential([\n",
    "    Dense(256, activation = 'relu'),\n",
    "    Dense(128, activation = 'relu'),\n",
    "    #ouputs 32 numbers\n",
    "    Dense(32),\n",
    "])\n",
    "num_user_features, num_item_features = 50,10\n",
    "\n",
    "#create user input and point to base network\n",
    "input_user = Input(shape = (num_user_features))\n",
    "vu = user_NN(input_user)\n",
    "#normalise vector for algorithm to work better\n",
    "vu = tf.linalg.l2_normalize(vu, axis = 1)\n",
    "\n",
    "#create item input and point to base network\n",
    "input_item = Input(shape = (num_item_features))\n",
    "vm = item_NN(input_item)\n",
    "vm = tf.linalg.l2_normalize(vm, axis = 1)\n",
    "\n",
    "#measure similarity of the two vector outputs\n",
    "output = Dot(axes = 1)([vu, vm])\n",
    "\n",
    "#specify inputs, ouputs of the model\n",
    "model = Model([input_user, input_item], output)\n",
    "\n",
    "#Specify cost function\n",
    "cost_fn = MeanSquaredError()\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
