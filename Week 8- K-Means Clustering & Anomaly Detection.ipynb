{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "651895c4",
   "metadata": {},
   "source": [
    "## A. Clustering\n",
    "- Unsupervised learning algorithm (Unlabelled Data)\n",
    "- Looks at data points and groups similar instances together\n",
    "\n",
    "\n",
    "**Applications**:\n",
    "1. Grouping similar news\n",
    "2. Market segmentation\n",
    "3. DNA Analysis\n",
    "4. Astronomical data analysis (Group bodies together)\n",
    "5. Image compression"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7887f14",
   "metadata": {},
   "source": [
    "### A1. K-means clustering"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "264f17e4",
   "metadata": {},
   "source": [
    "**K-means algorithm**:\n",
    "1. Randomly initialse $K$ cluster centroids $\\mu_1,\\mu_2,...\\mu_k$\n",
    "2. Repeat:\n",
    "    * Assign each data point to its closest centroids\n",
    "    * Recompute and move cluster centroids (Average of all respective data points)\n",
    "3. Stop when certain criteria is met: no further changes\n",
    "- A supervised machine learning classification tool\n",
    "- Regression (Regression trees)\n",
    "\n",
    "<img  src=\"./images/Wk8_1.png\"  style=\" width:80%; padding: 10px 20px ; \">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1581ee3c",
   "metadata": {},
   "source": [
    "### A2. Optimisation Objective\n",
    "- K-means algorithm has an underlying cost function (Distortion function)\n",
    "<img  src=\"./images/Wk8_2.png\"  style=\" width:70%; padding: 10px 20px ; \">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fed3238a",
   "metadata": {},
   "source": [
    "### A3. Initialising k-means"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58f20909",
   "metadata": {},
   "source": [
    "#### Random initialisation\n",
    "1. Choose $K < m$\n",
    "2. Randomly pick $K$ training examples\n",
    "3. Set $\\mu_1,\\mu_2,...\\mu_k$ equal to these $K$ examples\n",
    "<img  src=\"./images/Wk8_3.png\"  style=\" width:70%; padding: 10px 20px ; \">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1505563b",
   "metadata": {},
   "source": [
    "### A4. Choosing K"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dee71e1f",
   "metadata": {},
   "source": [
    "- Clustering is unsupervised, no clear indicator and is ambiguous\n",
    "\n",
    "#### Elbow method:\n",
    "- Look at cost function as function of K, and choosing number of clusters at the \"elbow\" \\\\_\n",
    "\n",
    "#### Evaluate K-means based on a metric for how well it performs for that later purpose"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9411854",
   "metadata": {},
   "source": [
    "## B. Anomaly detection\n",
    "- Another unsupervised learning algorithm\n",
    "- For finding/ detecting unusual events\n",
    "\n",
    "Applications:\n",
    "1. Aircraft engine anomaly/ Defects\n",
    "2. Fraud detection by identifying unusual users\n",
    "3. Monitoring Computers in Data Centers\n",
    "\n",
    "\n",
    "**Algorithm**:\n",
    "1. Plot all data points which are \"normal\"\n",
    "2. Anomaly is test data point which is away from other data points\n",
    "3. This is done through **density estimation** to decide if $x_{test}$ is anomalous\n",
    "    * Model $p(x)$ from data\n",
    "    * $p(x_{test}) < \\epsilon$ -> Flag anomaly  \n",
    "    * $p(x_{test}) >= \\epsilon$ -> \"ok\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "440e113a",
   "metadata": {},
   "source": [
    "### B1. Gaussian (Normal) Distribution"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d977c01a",
   "metadata": {},
   "source": [
    "**Aim**: To model p(x)\n",
    "\n",
    "$x(\\mu,\\sigma^2)$\n",
    "\n",
    "$$ p(x ; \\mu,\\sigma ^2) = \\frac{1}{\\sqrt{2 \\pi \\sigma ^2}}\\exp^{ - \\frac{(x - \\mu)^2}{2 \\sigma ^2} }$$\n",
    "\n",
    "   where $\\mu$ is the mean and $\\sigma^2$ controls the variance.\n",
    "   \n",
    "To estimate the mean, you will\n",
    "use:\n",
    "\n",
    "$$\\mu_i = \\frac{1}{m} \\sum_{j=1}^m x_i^{(j)}$$\n",
    "\n",
    "and for the variance you will use:\n",
    "$$\\sigma_i^2 = \\frac{1}{m} \\sum_{j=1}^m (x_i^{(j)} - \\mu_i)^2$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1706e4be",
   "metadata": {},
   "source": [
    "### B2. Anomaly Detection Algorithm using Density Estimation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e71ca4af",
   "metadata": {},
   "source": [
    "<img  src=\"./images/Wk8_4.png\"  style=\" width:70%; padding: 10px 20px ; \">\n",
    "<img  src=\"./images/Wk8_5.png\"  style=\" width:70%; padding: 10px 20px ; \">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c22cf947",
   "metadata": {},
   "source": [
    "### B3. Developing and Evaluating an Anomaly Detection System\n",
    "- How to choose $\\epsilon$\n",
    "\n",
    "- **Key**: Unlabelled training sets, with labelled cross-validation and test sets with anomalous data points\n",
    "    1. Train data and fit Gaussian distribution on train set\n",
    "    2. See how many anomalous data points it correctly flags on CV set\n",
    "    3. **Tune parameters($\\epsilon$) accordingly using CV set**\n",
    "    4.  Test model using test set\n",
    "<img  src=\"./images/Wk8_6.png\"  style=\" width:70%; padding: 10px 20px ; \">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c22b597",
   "metadata": {},
   "source": [
    "### B4. Algorithm Evaluation\n",
    "1. Fit model p(x) on training set $x^{(1)}, x^{(2)}, ... x^{(m)},$\n",
    "2. On a CV set, predict (y = 1 if $p(x) < \\epsilon$ (anomaly); y = 0 otherwise)\n",
    "3. Evaluation metrics:\n",
    "    * TP/FP/TN/FN\n",
    "    * Precision/Recall\n",
    "    * F1-Score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bdaaecb",
   "metadata": {},
   "source": [
    "### B5. Anomaly detection vs Supervised Learning\n",
    "- Since we're using labelled data, why not just used supervised learning?\n",
    "\n",
    "\n",
    "\n",
    "| data             | % of total | Description |\n",
    "|------------------|:----------:|:---------|\n",
    "| training         | 60         | Data used to tune model parameters $w$ and $b$ in training or fitting |\n",
    "| cross-validation | 20         | Data used to tune other model parameters like degree of polynomial, regularization or the architecture of a neural network.|\n",
    "| test             | 20         | Data used to test the model after tuning to gauge performance on new data |\n",
    "\n",
    "| Anomaly Detection | Supervised Learning|\n",
    "| :------------------:| :------------------:|\n",
    "| very small number of positive  examples (y=1)<br> large number of negative examples (y = 0)  | Large number of positive and negative examples \n",
    "|Many different \"types\" of anomalies<br> Hard for any algorithm to learn from positive examples what the anomalies look like<br>Future anomalies look different/nothing like it| Future positive likely to be similar to ones in training set\n",
    "|Compares to \"good\" and flag anything that deviates as bad/anomaly | Enough positve examples for algorithm to sense what positive examples are like\n",
    "|Fraud Detection|Email Spam Classification\n",
    "|Manufacturing - Finding new **previously unseen** defects| Manufacturing - Finding known, **previously seen** defects (scratches etc)\n",
    "|Monitoring machines in data center| Diseases classification\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1a3041a",
   "metadata": {},
   "source": [
    "### B6. Choosing what features to use\n",
    "- Good choice of features is crucial  \n",
    "- As opposed to supervised learning, which is more lenient towards extra/ lesser features\n",
    "- More important as it is trained on unlabelled dat###a\n",
    "\n",
    "#### KEY: USE GAUSSIAN FEATURES\n",
    "\n",
    "1. Non-gaussian features\n",
    "    * Plot histogram using `plt.hist`\n",
    "    * If skewed, transform using $log(x)$\n",
    "<img  src=\"./images/Wk8_7.png\"  style=\" width:70%; padding: 10px 20px ; \">    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57c2d885",
   "metadata": {},
   "source": [
    "### B7. Error analysis for anomaly detection\n",
    "\n",
    "Want  $p(x) < \\epsilon$ if y = 1 (anomaly); $p(x) >= \\epsilon$ otherwise  \n",
    "\n",
    "Most common problem:\n",
    "\n",
    "\n",
    "    * p(x) is comparable for normal and anomalous examples\n",
    "    * Solution: look at example and see what made it not flag correctly, and find another feature that distinguishes\n",
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39f7cc16",
   "metadata": {},
   "source": [
    "**Monitoring computers in a data center**\n",
    "\n",
    "Features:\n",
    "- $x_1 = $Memory use of computer \n",
    "- $x_2 = $Number of disk accesses/sec\n",
    "- $x_3 = $CPU load\n",
    "- $x_4 = $network traffic\n",
    "- $x_5 = \\frac{\\text{CPU Load}}{\\text{Network Traffic}}$\n",
    "- $x_6 = \\frac{(\\text{CPU Load})^2}{\\text{Network Traffic}}$\n",
    "\n",
    "Deciding feature choice based on p(x)\n",
    "- large for normal examples, becomes small for anomalies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20f9c572",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
