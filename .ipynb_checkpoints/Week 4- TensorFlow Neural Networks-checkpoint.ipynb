{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "487865ce",
   "metadata": {},
   "source": [
    "## Neural Networks\n",
    "- inference (prediction)\n",
    "- training"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed003a2b",
   "metadata": {},
   "source": [
    "### Neurons and the brain"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0afbcac7",
   "metadata": {},
   "source": [
    "Neural networks try to mimic the brain.  \n",
    "speech recognition > images (computer vision) > text (NLP) .."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae227cec",
   "metadata": {},
   "source": [
    "### Neural network architecture\n",
    "- Consist of \n",
    " 1. Input layer (vector of inputs) $\\vec{x}$\n",
    " 2. Hidden layer - multiple neurons (vector of activation values) $\\vec{a}$\n",
    " 3. Output layer\n",
    "- Can have multiple hidden layers (multi-layer perceptron)\n",
    "- Choosing appropriate architecture ( no of hidden layers and nodes per hidden layer) affects performance"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed61acdd",
   "metadata": {},
   "source": [
    "### Recognising Images (Computer Vision)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f850cb78",
   "metadata": {},
   "source": [
    "1. Concept: Input image > Output\n",
    " - Face recognition: Image > Identity of person in picture\n",
    " - If 1000x1000 pixels it will be converted to matrix, each pixel ranges from 0 to 255\n",
    " - Become a list/ feature vector of 1,000,000 pixel intensity values\n",
    " - $\\vec{x}$ > Hideen layers > probability of person being 'XYZ'\n",
    " - Each hidden layer window progressively getting bigger (lines > singular face parts > portions of face)\n",
    " - Activations are higher level features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "428e71ad",
   "metadata": {},
   "source": [
    "### Neural network layer (A layer of neurons)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6da3ff7",
   "metadata": {},
   "source": [
    "- Each neuron has its own logistic regression unit\n",
    "- Neurons (has parameters w1,b1; w2,b2) ... and outputs vector activation values\n",
    "- $\\vec{a}^{[1]}$ - Activation value vector of layer 1\n",
    "-  $\\vec{a}^{[1]}$ becomes input for layer 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f825535d",
   "metadata": {},
   "source": [
    "<figure>\n",
    "   <img src=\"./images/Week4_1.png\"  style=\"width:540px;height:300px;\" >\n",
    "</figure>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9808e0e",
   "metadata": {},
   "source": [
    " ${\\large  \\vec{a}^{[l]}_j = g({\\vec{w}^{[l]}_j} \\centerdot \\vec{a}^{[l-1]} + \\vec{b}^{[l]}_j)}$  \n",
    " $\\vec{a}^{[l]}_j$ = Activation value of layer $l$, unit(neuron) $j$  \n",
    " ${\\vec{w}^{[l]}_j}$, $\\vec{b}^{[l]}_j$ = Parameters $w,b$ of layer $l$, unit(neuron) $j$  \n",
    " $\\vec{a}^{[l-1]}$ = output of layer $l-1$(previous layer)  \n",
    " $g$ = sigmoid / activation function\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2650f63b",
   "metadata": {},
   "source": [
    "### Inference: Making predicitons (forward propagation)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "861e45ba",
   "metadata": {},
   "source": [
    "### Building models using TensorFlow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a474a7a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.layers import Dense, Input\n",
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras.losses import MeanSquaredError, BinaryCrossentropy\n",
    "from tensorflow.keras.activations import sigmoid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d081b0ca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[200.,  17.]])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = np.array([[200.0, 17.0]])\n",
    "layer_1 = Dense(units=3, activation='sigmoid')\n",
    "a1=layer_1(x)\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "39f28fed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1, 1), dtype=float32, numpy=array([[0.2483764]], dtype=float32)>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "layer_2 = Dense(units=1, activation='sigmoid')\n",
    "a2=layer_2(a1)\n",
    "a2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eacde210",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
