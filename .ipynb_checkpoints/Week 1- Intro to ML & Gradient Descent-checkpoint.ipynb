{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dc3fd477",
   "metadata": {},
   "source": [
    "## ML Algorithms\n",
    "1. Supervised learning\n",
    "2. Unsupervised Learning\n",
    "3. Recommender Systems\n",
    "4. Reinforcement learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fd7b7fda",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as pl\n",
    "import numpy as np\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ce5be93",
   "metadata": {},
   "source": [
    "## Supervised Learning\n",
    "- Training based on labelled data(input and output)\n",
    "- Tested based on ability to guess output/label given input features\n",
    "- Regression, Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be39b908",
   "metadata": {},
   "source": [
    "Application:\n",
    "-Spam filltering, Speech recognition, machine translation, self driving cars.."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca906ef6",
   "metadata": {},
   "source": [
    "Eg: Regression- Housing price prediction (Continuous)\n",
    "1. Input- House size\n",
    "2. Output- Price"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff7e127f",
   "metadata": {},
   "source": [
    "Eg: Classification- Breast cancer detection (Discrete)\n",
    "1. Input- tumor size\n",
    "2. Output- Malignant/benign"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bd82a82",
   "metadata": {},
   "source": [
    "## Unsupervised learning\n",
    "- Only given unlabelled data, find patterns or structures within data\n",
    "1. Clustering- Group simiar data points together\n",
    "2. Anomaly detection- Find unusual data points\n",
    "3. Dimensionality reduction- Compress data using fewer numbers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22816d02",
   "metadata": {},
   "source": [
    "#### Clustering\n",
    "Eg: Google News\n",
    "- Cluster similar articles together\n",
    "- Mention similar words/ content etc\n",
    "- algorithm figure out without supervision\n",
    "\n",
    "Eg2: DNA microarray\n",
    "- Group individuals based on trait\n",
    "\n",
    "Eg3: Grouping customers\n",
    "- Market segmentation found distinct group of individuals (grow skills/ develop career/ stay updated)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f35b7922",
   "metadata": {},
   "source": [
    "## Linear Regression Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9ad326c",
   "metadata": {},
   "source": [
    "- Train model based on \"right\" data\n",
    "- Fit a straight line through data points"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14d583a9",
   "metadata": {},
   "source": [
    "Training set > Learning algroithm > f(model) > predict Å·"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15028102",
   "metadata": {},
   "source": [
    "How to represent $f$?  \n",
    "\n",
    "$ f_{w,b} (x) = wx + b$   or  $f(x)$  (Linear)\n",
    "- Linear regression with one variable\n",
    "- Univariate linear regression\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27b73b83",
   "metadata": {},
   "source": [
    "## Cost Function\n",
    "- Mean squared error\n",
    "- Formula:  $$J(w,b) = \\frac{1}{2m} \\sum\\limits_{i = 0}^{m-1} (f_{w,b}(x^{(i)}) - y^{(i)})^2 \\tag{1}$$\n",
    "- parameters: $w, b$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52832a22",
   "metadata": {},
   "source": [
    "Algorithm to train linear regression/ complex models/ neural networks:  \n",
    "   ## Gradient Descent"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f471348",
   "metadata": {},
   "source": [
    "Minimise  $J(w,b)$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b567c25f",
   "metadata": {},
   "source": [
    "1. Start with some w,b\n",
    "2. Keep changing w,b to reduce cost\n",
    "3. Until we settle at a minimum ( might have more than one min/ local minima)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "117297ac",
   "metadata": {},
   "source": [
    "### Gradient Descent Algorithm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96ae9c2d",
   "metadata": {},
   "source": [
    "$$\\begin{align*} \\text{repeat}&\\text{ until convergence:} \\; \\lbrace \\newline\n",
    "\\;  w &= w -  \\alpha \\frac{\\partial J(w,b)}{\\partial w} \\tag{3}  \\; \\newline \n",
    " b &= b -  \\alpha \\frac{\\partial J(w,b)}{\\partial b}  \\newline \\rbrace\n",
    "\\end{align*}$$\n",
    "where, parameters $w$, $b$ are updated simultaneously, $\\alpha$ is learning rate.  \n",
    "The gradient is defined as:\n",
    "$$\n",
    "\\begin{align}\n",
    "\\frac{\\partial J(w,b)}{\\partial w}  &= \\frac{1}{m} \\sum\\limits_{i = 0}^{m-1} (f_{w,b}(x^{(i)}) - y^{(i)})x^{(i)} \\tag{4}\\\\\n",
    "  \\frac{\\partial J(w,b)}{\\partial b}  &= \\frac{1}{m} \\sum\\limits_{i = 0}^{m-1} (f_{w,b}(x^{(i)}) - y^{(i)}) \\tag{5}\\\\\n",
    "\\end{align}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b61b7282",
   "metadata": {},
   "source": [
    "### Learning rate"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e7dfd0c",
   "metadata": {},
   "source": [
    "If $\\alpha$ is too small, gradient descent will work but gradient descent algorithm will be very slow.  \n",
    "If $\\alpha$ is too large, may never reach minimum as overshoot, gradient descent fail to converge.   \n",
    "However, it can reach local minimum with fixed learning rate as derivative becomes smaller when approaching local minimum. (Update steps become smaller)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d43942a1",
   "metadata": {},
   "source": [
    "### Vectorisation\n",
    "- Make implementation of learning algorithms shorter and \n",
    "- utilise modern linear algebra libraries\n",
    "- Utilise GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6afba625",
   "metadata": {},
   "outputs": [],
   "source": [
    "# start_time = time.time()\n",
    "w = np.array([1.0, 2.5, -3.3])\n",
    "b = 4\n",
    "x = np.array([10, 20, 30])\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f465f4f4",
   "metadata": {},
   "source": [
    "Without vecotrisation, need for loop to sum all.  \n",
    "With vectorisation, can use dot product."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3d883be7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-35.0"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f = np.dot(w, x) + b\n",
    "f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "76b3e7b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time for loop dot product: 0.08069 seconds\n",
      "Time for numpy dot product: 0.00000 seconds\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Define vector size\n",
    "vector_size = 100000\n",
    "\n",
    "# Create random vectors\n",
    "vector_a = np.random.rand(vector_size)\n",
    "vector_b = np.random.rand(vector_size)\n",
    "\n",
    "# Time for loop dot product\n",
    "import time\n",
    "\n",
    "start_loop = time.time()\n",
    "dot_product_loop = 0\n",
    "for i in range(vector_size):\n",
    "    dot_product_loop += vector_a[i] * vector_b[i]\n",
    "end_loop = time.time()\n",
    "\n",
    "# Time numpy dot product\n",
    "start_numpy = time.time()\n",
    "dot_product_numpy = np.dot(vector_a, vector_b)\n",
    "end_numpy = time.time()\n",
    "\n",
    "# Calculate and print execution times\n",
    "time_loop = end_loop - start_loop\n",
    "time_numpy = end_numpy - start_numpy\n",
    "\n",
    "print(f\"Time for loop dot product: {time_loop:.5f} seconds\") # 5.95863 seconds (10,000,000)\n",
    "print(f\"Time for numpy dot product: {time_numpy:.5f} seconds\") #0.00598 seconds (1000 times faster)!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e18cfb88",
   "metadata": {},
   "source": [
    "### How does vectorisation work?\n",
    "- Multiplies all corresponding pairs simultaneously/ in parallel\n",
    "- Machine adds all products efficiently"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1286ddda",
   "metadata": {},
   "source": [
    "- In gradient descent, we might have many input features stored as a vector\n",
    "- With vectorisation, gradient descent runs in parallel much faster than using for loops"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4e151ab",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
