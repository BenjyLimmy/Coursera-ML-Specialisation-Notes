{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b4d0bbb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as pl\n",
    "import numpy as np\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d8f3d41",
   "metadata": {},
   "source": [
    "## Gradient descent for multiple regression"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7645f67",
   "metadata": {},
   "source": [
    "Vector notation:\n",
    "- $w = [w1,  w2,  w3, .. wn]$\n",
    "- $ f_{\\mathbf{w},b}(\\mathbf{x}) = \\mathbf{w} \\cdot \\mathbf{x} + b $ \n",
    "- Scikit-learn: SDGRegression"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80fa9ebc",
   "metadata": {},
   "source": [
    "Gradient descent for multiple variables:\n",
    "\n",
    "$$\\begin{align*} \\text{repeat}&\\text{ until convergence:} \\; \\lbrace \\newline\\;\n",
    "& w_j = w_j -  \\alpha \\frac{\\partial J(\\mathbf{w},b)}{\\partial w_j} \\tag{5}  \\; & \\text{for j = 0..n-1}\\newline\n",
    "&b\\ \\ = b -  \\alpha \\frac{\\partial J(\\mathbf{w},b)}{\\partial b}  \\newline \\rbrace\n",
    "\\end{align*}$$\n",
    "\n",
    "where, n is the number of features, parameters $w_j$,  $b$, are updated simultaneously and where  \n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    "\\frac{\\partial J(\\mathbf{w},b)}{\\partial w_j}  &= \\frac{1}{m} \\sum\\limits_{i = 0}^{m-1} (f_{\\mathbf{w},b}(\\mathbf{x}^{(i)}) - y^{(i)})x_{j}^{(i)} \\tag{6}  \\\\\n",
    "\\frac{\\partial J(\\mathbf{w},b)}{\\partial b}  &= \\frac{1}{m} \\sum\\limits_{i = 0}^{m-1} (f_{\\mathbf{w},b}(\\mathbf{x}^{(i)}) - y^{(i)}) \\tag{7}\n",
    "\\end{align}\n",
    "$$\n",
    "* m is the number of training examples in the data set\n",
    "\n",
    "    \n",
    "*  $f_{\\mathbf{w},b}(\\mathbf{x}^{(i)})$ is the model's prediction, while $y^{(i)}$ is the target value"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "028407f3",
   "metadata": {},
   "source": [
    "###  Feature Scaling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60c2ba26",
   "metadata": {},
   "source": [
    "- Makes gradient descent work faster\n",
    "- Example: land size (feature) has a large feature size but low parameter size\n",
    "- Opposite is true for number of rooms (feature)\n",
    "- This will cause many iterations to find minimum in contour due to difference in scales"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d52a8f7b",
   "metadata": {},
   "source": [
    "#### Thus, we need feature scaling.\n",
    "- Put values in range 0 to 1 so both have equal scales/ comparable range of values."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "804a41a0",
   "metadata": {},
   "source": [
    "1. Divide values by max value\n",
    "2. Mean normalisation = $\\frac{x_1 - mean_1}{max-min}$ Range: -0.18<x<0.82\n",
    "3. Z-score normalisation = calc mean and sd $\\frac{x_1 - mean_1}{sd}$\n",
    "\n",
    "- Aim for about $-1<=x_j<=1$ for each feature $x_j$, ensure range is not too large or not too small"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1d68ea4",
   "metadata": {},
   "source": [
    "### Checking Gradient Descent for Convergence\n",
    "\n",
    "- Aim: find min $J(w,b)$\n",
    "- Plot number of iterations and cost, should see learning curve(decreasing)\n",
    "- If J increases, it means learning rate is chosen poorly\n",
    "- Converge when line flattens\n",
    "- Automatic converge test- let $\\epsilon = 10^-3$ declare convergence when $J(w.b)$ decreases by $<= \\epsilon$ in one iteration, i.e. found parameters w,b at global minimum"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6983b722",
   "metadata": {},
   "source": [
    "### Feature engineering\n",
    "- Choice of features have huge impact on learning algorithms performance\n",
    "- Using intuition to design new features, by transforming/combining original features\n",
    "- Eg: Combine two features (frontage and depth) to form new feature (area)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68fc09a2",
   "metadata": {},
   "source": [
    "### Polynomial Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0576377a",
   "metadata": {},
   "source": [
    "- Straight line may not fit data set well\n",
    "- Need higher order regression (quadratic, cubic..)\n",
    "- Eg: $f_{w,b}(x) = w_1x + w_2x^2 + w_3x^3 + b$, where x is a feature\n",
    "- Combine with feature scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bd715c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
